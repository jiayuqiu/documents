## 1. 留出法
“留出法”（hold-out）直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，即D=S∪T，S∩T=∅。
在S上训练出模型后，用T来评估其测试误差，作为泛化误差（泛化：学得模型适用于新样本的能力；泛化误差：在新样本上的误差）的估计。

### 注意1：
训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响，例如在分类任务中至少要保持样本的类别比例相似。
例1：若样本总数为100，其中70为正例，30为反例。那么在选取70%训练集时，应选取49正例与21反例。

### 注意2：
即便在给定训练/测试集的样本比例后，仍存在多种划分方式对初始数据集D进行分割。一般情况下，不同的划分将产生不同的评估结果。因此，单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后去平均值作为留出法的评估结果。

#### 留出法的分割方法没有完美的分割方法，常见做法是将大约2/3~4/5的样本用于训练，剩余样本作用于测试。
