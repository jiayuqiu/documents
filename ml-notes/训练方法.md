## 1. 留出法
```“留出法”```（hold-out）直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，即D=S∪T，S∩T=∅。
在S上训练出模型后，用T来评估其测试误差，作为泛化误差（泛化：学得模型适用于新样本的能力；泛化误差：在新样本上的误差）的估计。

### 注意1：
训练/测试集的划分要尽可能保持数据分布的```一致性```，避免因数据划分过程引入额外的偏差而对最终结果产生影响，例如在分类任务中至少要保持样本的类别比例相似。
例1：若样本总数为100，其中70为正例，30为反例。那么在选取70%训练集时，应选取49正例与21反例。

### 注意2：
即便在给定训练/测试集的样本比例后，仍存在多种划分方式对初始数据集D进行分割。```一般情况下，不同的划分将产生不同的评估结果```。因此，单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，```一般要采用若干次随机划分、重复进行实验评估后取平均值```作为留出法的评估结果。

#### 留出法的分割方法没有完美的分割方法，常见做法是将大约2/3~4/5的样本用于训练，剩余样本作用于测试。

## 2. 交叉验证法
```交叉验证法```也称为```k折交叉验证```。
- 先将数据集D分为k个大小相似的```互斥子集```，即D=D1∪D2∪...∪Dk，Di∩Dj=∅（i≠j）。每个子集Di都尽可能保持数据分布的一致性。
- 然后，每次用```k-1个子集的并集```作为训练集，```余下的那个子集```作为测试集；这样就可以获得k组训练/测试集用于训练和测试。
- 最终返回k个测试结果的均值作为评估结果。
- 显然，这种做法产生的结果的稳定性和保真性在很大程度上取决与k的取值。常用的k的值为```10```。



### 特例：
```留一法```：假定数据集D包含m个样本，若令k=m，那么得到了交叉验证法的一个特例，即：```留一法```。
![image](https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Markdown-mark.svg/208px-Markdown-mark.svg.png)
