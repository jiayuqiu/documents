## 1. 基本形式
给定由d个属性描述的示例x=(x<sub>1</sub>;x<sub>2</sub>;...;x<sub>d</sub>)，其中xi是x在第i个属性上的取值，线性模型视图学得一个通过属性的线性组合来进行预测的函数，即

![image](./images/线性模型基本形式1.png)

一般用向量形式写成：

![image](./images/线性模型基本形式2.png)

其中，w=(w<sub>1</sub>;w<sub>2</sub>;...;w<sub>d</sub>)。w和b学得之后，模型就得以确定。

---

## 2. 线性回归
给定数据集D = {(x<sub>1</sub>, y<sub>1</sub>), (x<sub>2</sub>, y<sub>2</sub>), (x<sub>m</sub>, y<sub>m</sub>)}，其中x<sub>i</sub>=(x<sub>i1</sub>;x<sub>i2</sub>;...;x<sub>id</sub>)，y<sub>i</sub>∈R。

```线性回归试图学得一个线性模型，以尽可能准确地预测实际值。在输入值的时候需要注意，若将无序属性连续化则会不恰当地引入序关系，会对后续处理比如距离计算造成误差。例：{1, 2, 3}，“1”与“2”相近，而“2”与“3”相近；｛飞机，汽车，大炮｝之间没有序关系，应表示为向量｛0, 0, 1｝、｛0, 1, 0｝、｛1,0, 0｝```

令f(x<sub>i</sub>) = wx<sub>i</sub>+b，使得f(x<sub>i</sub>)≈y<sub>i</sub>。在确定w和b的过程中，均方误差是最常用的性能度量，因此需要让均方误差最小化，即：

![image](./images/均方误差最小化公式.png)

均方误差有很好的几何意义，它对应了常用的欧几里得距离或简称“欧氏距离”。基于均方误差```最小化```来进行模拟求解的方法称为```“最小二乘法”```。在线性回归中，最小二乘法就是试图找到一条直线，使得所有样本到直线上的欧式距离之和最小。

![img](http://latex.codecogs.com/gif.latex?E_%7B%5Comega%20%2C%20b%7D%20%3D%20%5Csum_%7Bi%3D1%7D%5Em%20%28y_%7Bi%7D%20-%20%5Comega%20x_%7Bi%7D%20-%20b%29%20%5E%7B2%7D) 

对上述公式分别对w和b求偏导数，得到

![1527945718922](E:\workspace\documents\ml-notes\images\1527945718922.png)

然后，令上面两个等式为零，则得到w和b最优解的闭式解。

​线性模型虽然简单，但是有着丰富的变化，可拓展为对数线性回归，即：

![1527945991391](./images/1527945991391.png)

实际上就是做了非线性映射

![1527946036838](./images/1527946036838.png)


极大似然估计

总结起来，最大似然估计的目的就是：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。

原理：极大似然估计是建立在极大似然原理的基础上的一个统计方法，是概率论在统计学中的应用。极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。通过若干次试验，观察其结果，利用试验结果得到某个参数值能够使样本出现的概率为最大，则称为极大似然估计。

https://blog.csdn.net/zengxiantao1994/article/details/72787849

https://blog.csdn.net/u011508640/article/details/72815981/